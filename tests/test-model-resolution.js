#!/usr/bin/env node

import { readFileSync, statSync } from 'fs';

console.log('üîç Testing Model Path Resolution Implementation...\n');

// Test 1: Verify Rust backend changes
console.log('1. Testing Rust backend model resolution...');
try {
  const rustContent = readFileSync('src-tauri/src/llm.rs', 'utf8');
  
  if (rustContent.includes('model_filename: String')) {
    console.log('   ‚úÖ Rust LlmConfig uses model_filename field');
  } else {
    console.log('   ‚ùå Rust LlmConfig still uses model_path field');
  }
  
  if (rustContent.includes('resolve_model_path')) {
    console.log('   ‚úÖ Rust path resolution function implemented');
  } else {
    console.log('   ‚ùå Rust path resolution function missing');
  }
  
  if (rustContent.includes('models_dir = current_dir.join("models")')) {
    console.log('   ‚úÖ Rust correctly constructs models directory path');
  } else {
    console.log('   ‚ùå Rust models directory path construction missing');
  }
  
} catch (error) {
  console.log('   ‚ùå Error reading Rust file:', error.message);
}

// Test 2: Verify TypeScript frontend changes
console.log('\n2. Testing TypeScript frontend changes...');
try {
  const tsTypesContent = readFileSync('src/types/llm.ts', 'utf8');
  
  if (tsTypesContent.includes('model_filename: string')) {
    console.log('   ‚úÖ TypeScript LlmConfig uses model_filename field');
  } else {
    console.log('   ‚ùå TypeScript LlmConfig still uses model_path field');
  }
  
  if (!tsTypesContent.includes('model_path: string')) {
    console.log('   ‚úÖ TypeScript LlmConfig no longer has model_path field');
  } else {
    console.log('   ‚ùå TypeScript LlmConfig still has model_path field');
  }
  
} catch (error) {
  console.log('   ‚ùå Error reading TypeScript types file:', error.message);
}

// Test 3: Verify configuration changes
console.log('\n3. Testing configuration changes...');
try {
  const configContent = readFileSync('src/config/app.ts', 'utf8');
  
  if (configContent.includes('model_filename: "Llama-3.2-1B-Instruct-Q5_K_M.gguf"')) {
    console.log('   ‚úÖ App config uses model_filename with correct default');
  } else {
    console.log('   ‚ùå App config model_filename not updated');
  }
  
  if (configContent.includes('validateModelFilename')) {
    console.log('   ‚úÖ Model filename validation function implemented');
  } else {
    console.log('   ‚ùå Model filename validation function missing');
  }
  
  if (configContent.includes('validateLlmConfig')) {
    console.log('   ‚úÖ LLM config validation function implemented');
  } else {
    console.log('   ‚ùå LLM config validation function missing');
  }
  
} catch (error) {
  console.log('   ‚ùå Error reading config file:', error.message);
}

// Test 4: Verify component changes
console.log('\n4. Testing component changes...');
try {
  const panelContent = readFileSync('src/components/LlmServicePanel.tsx', 'utf8');
  
  if (panelContent.includes('Model Filename:')) {
    console.log('   ‚úÖ LlmServicePanel uses "Model Filename" label');
  } else {
    console.log('   ‚ùå LlmServicePanel still uses "Model Path" label');
  }
  
  if (panelContent.includes('localConfig.model_filename')) {
    console.log('   ‚úÖ LlmServicePanel accesses model_filename field');
  } else {
    console.log('   ‚ùå LlmServicePanel still accesses model_path field');
  }
  
  const settingsContent = readFileSync('src/components/AppSettings.tsx', 'utf8');
  
  if (settingsContent.includes('Model Filename:')) {
    console.log('   ‚úÖ AppSettings uses "Model Filename" label');
  } else {
    console.log('   ‚ùå AppSettings still uses "Model Path" label');
  }
  
} catch (error) {
  console.log('   ‚ùå Error reading component files:', error.message);
}

// Test 5: Verify model file exists
console.log('\n5. Testing model file availability...');
try {
  const modelFile = statSync('models/Llama-3.2-1B-Instruct-Q5_K_M.gguf');
  if (modelFile.isFile()) {
    const sizeMB = (modelFile.size / (1024 * 1024)).toFixed(2);
    console.log(`   ‚úÖ Model file exists: ${sizeMB} MB`);
    console.log('   ‚úÖ Backend should be able to resolve this filename to full path');
  } else {
    console.log('   ‚ùå Model file not accessible');
  }
} catch (error) {
  console.log('   ‚ùå Model file not found:', error.message);
  console.log('   ‚ö†Ô∏è  Backend will show appropriate error message');
}

// Test 6: Verify hooks changes
console.log('\n6. Testing hooks changes...');
try {
  const hooksContent = readFileSync('src/hooks/useLlm.ts', 'utf8');
  
  if (!hooksContent.includes('resolveModelPath')) {
    console.log('   ‚úÖ useLlm hook no longer calls resolveModelPath');
  } else {
    console.log('   ‚ùå useLlm hook still calls resolveModelPath');
  }
  
  if (hooksContent.includes('// Use the config directly - the backend will resolve the model path')) {
    console.log('   ‚úÖ useLlm hook has correct comment about backend resolution');
  } else {
    console.log('   ‚ùå useLlm hook comment not updated');
  }
  
} catch (error) {
  console.log('   ‚ùå Error reading hooks file:', error.message);
}

console.log('\nüéØ Implementation Summary:');
console.log('   ‚Ä¢ Frontend now sends only model filenames (e.g., "Llama-3.2-1B-Instruct-Q5_K_M.gguf")');
console.log('   ‚Ä¢ Backend automatically resolves full paths by combining project root + "models" + filename');
console.log('   ‚Ä¢ Path resolution happens in Rust backend using resolve_model_path() method');
console.log('   ‚Ä¢ Frontend validation ensures .gguf extension and valid filename format');
console.log('   ‚Ä¢ Error messages include helpful information about models directory location');

console.log('\n‚úÖ Model path resolution implementation complete!');
console.log('   The "Model file not found" error should now be resolved.');
